{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e181e0a-be8a-4033-be60-9a967fd455e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.912028118634735\n"
     ]
    }
   ],
   "source": [
    "include(\"structure.jl\")\n",
    "include(\"backward.jl\")\n",
    "include(\"forward.jl\")\n",
    "include(\"graph.jl\")\n",
    "include(\"brodcasted_operators.jl\")\n",
    "\n",
    "x = Variable(5.0, name=\"x\")\n",
    "two = Constant(2.0)\n",
    "squared = x^two\n",
    "sine = sin(squared)\n",
    "\n",
    "order = topological_sort(sine)\n",
    "y = forward!(order)\n",
    "backward!(order)\n",
    "\n",
    "println(x.gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4848e2-1149-44b0-9b08-94112ef6a950",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: invalid \"::\" syntax around C:\\workdir\\usr\\share\\julia\\stdlib\\v1.10\\Test\\src\\Test.jl:669",
     "output_type": "error",
     "traceback": [
      "syntax: invalid \"::\" syntax around C:\\workdir\\usr\\share\\julia\\stdlib\\v1.10\\Test\\src\\Test.jl:669",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[7]:9"
     ]
    }
   ],
   "source": [
    "using Test\n",
    "\n",
    "# Define the recurrent function\n",
    "function recurrent(x::Matrix{Float64}, Wxh::Matrix{Float64}, h::Matrix{Float64}, Whh::Matrix{Float64})\n",
    "    return Wxh * x + Whh * h\n",
    "end\n",
    "\n",
    "# Define a simple test case\n",
    "function test_recurrent()\n",
    "    # Define input matrices\n",
    "    x = randn(3, 2)  # Example input matrix (3 features, 2 samples)\n",
    "    Wxh = randn(4, 3)  # Example weight matrix for input\n",
    "    h = randn(4, 2)  # Example hidden state matrix\n",
    "    Whh = randn(4, 4)  # Example weight matrix for hidden state\n",
    "\n",
    "    # Compute forward pass\n",
    "    ht_expected = recurrent(x, Wxh, h, Whh)\n",
    "\n",
    "    # Compute gradients for backward pass (this depends on your implementation)\n",
    "    dL_dht = randn(size(ht_expected))\n",
    "\n",
    "    # Compute gradients using backward pass (assuming your implementation)\n",
    "    dL_dx_expected = Wxh' * dL_dht\n",
    "    dL_dWxh_expected = dL_dht * x'\n",
    "    dL_dh_expected = Whh' * dL_dht\n",
    "    dL_dWhh_expected = dL_dht * h'\n",
    "\n",
    "    # Perform the forward pass and compare with expected result\n",
    "    @test recurrent(x, Wxh, h, Whh) â‰ˆ ht_expected atol=1e-6\n",
    "\n",
    "    # Perform the backward pass and compare with expected gradients\n",
    "    @test backward(::typeof(recurrent), x, Wxh, h, Whh, dL_dht) == (dL_dx_expected, dL_dWxh_expected, dL_dh_expected, dL_dWhh_expected)\n",
    "end\n",
    "\n",
    "# Run the test\n",
    "test_recurrent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c42a324-5c43-4db5-8f7e-455f008a0898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: invalid \"::\" syntax around In[8]:32",
     "output_type": "error",
     "traceback": [
      "syntax: invalid \"::\" syntax around In[8]:32",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[8]:9"
     ]
    }
   ],
   "source": [
    "using Test\n",
    "\n",
    "# Define the recurrent function\n",
    "function recurrent(x::Matrix{Float64}, Wxh::Matrix{Float64}, h::Matrix{Float64}, Whh::Matrix{Float64})\n",
    "    return Wxh * x + Whh * h\n",
    "end\n",
    "\n",
    "# Define a simple test case\n",
    "function test_recurrent()\n",
    "    # Define input matrices\n",
    "    x = randn(3, 2)  # Example input matrix (3 features, 2 samples)\n",
    "    Wxh = randn(4, 3)  # Example weight matrix for input\n",
    "    h = randn(4, 2)  # Example hidden state matrix\n",
    "    Whh = randn(4, 4)  # Example weight matrix for hidden state\n",
    "\n",
    "    # Compute forward pass\n",
    "    ht_expected = recurrent(x, Wxh, h, Whh)\n",
    "\n",
    "    # Compute gradients for backward pass (this depends on your implementation)\n",
    "    dL_dht = randn(size(ht_expected))\n",
    "\n",
    "    # Compute gradients using backward pass (assuming your implementation)\n",
    "    dL_dx_expected = Wxh' * dL_dht\n",
    "    dL_dWxh_expected = dL_dht * x'\n",
    "    dL_dh_expected = Whh' * dL_dht\n",
    "    dL_dWhh_expected = dL_dht * h'\n",
    "\n",
    "    # Perform the forward pass and compare with expected result\n",
    "    @test isapprox(recurrent(x, Wxh, h, Whh), ht_expected, atol=1e-6)\n",
    "\n",
    "    # Perform the backward pass and compare with expected gradients\n",
    "    grads = backward(::typeof(recurrent), x, Wxh, h, Whh, dL_dht)\n",
    "    @test isapprox(grads[1], dL_dx_expected, atol=1e-6)\n",
    "    @test isapprox(grads[2], dL_dWxh_expected, atol=1e-6)\n",
    "    @test isapprox(grads[3], dL_dh_expected, atol=1e-6)\n",
    "    @test isapprox(grads[4], dL_dWhh_expected, atol=1e-6)\n",
    "end\n",
    "\n",
    "# Run the test\n",
    "test_recurrent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61cd915-17d9-4d0b-ac2e-4ddcf082bc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
