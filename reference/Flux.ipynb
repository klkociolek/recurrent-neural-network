{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36740fc0-1a10-491b-9605-9f28761421fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Recur(\n",
       "    RNNCell(196 => 64, tanh),           \u001b[90m# 16_768 parameters\u001b[39m\n",
       "  ),\n",
       "  Dense(64 => 10),                      \u001b[90m# 650 parameters\u001b[39m\n",
       ") \u001b[90m        # Total: 6 trainable arrays, \u001b[39m17_418 parameters,\n",
       "\u001b[90m          # plus 1 non-trainable, 64 parameters, summarysize \u001b[39m68.406 KiB."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opracowane na podstawie https://minpy.readthedocs.io/en/latest/tutorial/rnn_mnist.html\n",
    "using MLDatasets, Flux\n",
    "train_data = MLDatasets.MNIST(split=:train)\n",
    "test_data  = MLDatasets.MNIST(split=:test)\n",
    "\n",
    "function loader(data; batchsize::Int=1)\n",
    "    x1dim = reshape(data.features, 28 * 28, :) # reshape 28×28 pixels into a vector of pixels\n",
    "    yhot  = Flux.onehotbatch(data.targets, 0:9) # make a 10×60000 OneHotMatrix\n",
    "    Flux.DataLoader((x1dim, yhot); batchsize, shuffle=true)\n",
    "end\n",
    "\n",
    "net = Chain(\n",
    "    RNN((14 * 14) => 64, tanh),\n",
    "    Dense(64 => 10, identity),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5902b044-e42a-43d8-88d6-624968d3b473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_and_accuracy(net, test_data) = (loss = 2.4164934f0, acc = 10.14, split = :test)\n"
     ]
    }
   ],
   "source": [
    "using Statistics: mean  # standard library\n",
    "function loss_and_accuracy(model, data)\n",
    "    (x,y) = only(loader(data; batchsize=length(data)))\n",
    "    Flux.reset!(model)\n",
    "    ŷ = model(x[  1:196,:])\n",
    "    ŷ = model(x[197:392,:])\n",
    "    ŷ = model(x[393:588,:])\n",
    "    ŷ = model(x[589:end,:])\n",
    "    loss = Flux.logitcrossentropy(ŷ, y)  # did not include softmax in the model\n",
    "    acc = round(100 * mean(Flux.onecold(ŷ) .== Flux.onecold(y)); digits=2)\n",
    "    (; loss, acc, split=data.split)  # return a NamedTuple\n",
    "end\n",
    "\n",
    "@show loss_and_accuracy(net, test_data);  # accuracy about 10%, before training\n",
    "\n",
    "train_log = []\n",
    "settings = (;\n",
    "    eta = 15e-3,\n",
    "    epochs = 5,\n",
    "    batchsize = 100,\n",
    ")\n",
    "\n",
    "opt_state = Flux.setup(Descent(settings.eta), net);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08814dad-ee1a-4410-a3b3-4ea58e7a9332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.463706 seconds (833.63 k allocations: 2.647 GiB, 12.72% gc time, 22.46% compilation time)\n",
      "  6.676800 seconds (541.34 k allocations: 2.630 GiB, 4.97% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m1\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  acc = 89.62\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 90.08\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  acc = 91.87\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 92.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.012503 seconds (541.34 k allocations: 2.630 GiB, 6.92% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m3\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  acc = 92.96\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 93.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.644309 seconds (541.34 k allocations: 2.630 GiB, 6.81% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m4\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  acc = 93.71\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 93.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.552978 seconds (541.34 k allocations: 2.630 GiB, 7.21% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m5\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  acc = 94.27\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 94.36\n"
     ]
    }
   ],
   "source": [
    "using ProgressMeter\n",
    "\n",
    "for epoch in 1:settings.epochs\n",
    "    @time for (x,y) in loader(train_data, batchsize=settings.batchsize)\n",
    "        Flux.reset!(net)\n",
    "        grads = Flux.gradient(model -> let\n",
    "                ŷ = model(x[  1:196,:])\n",
    "                ŷ = model(x[197:392,:])\n",
    "                ŷ = model(x[393:588,:])\n",
    "                ŷ = model(x[589:end,:])\n",
    "                Flux.logitcrossentropy(ŷ, y)\n",
    "            end, net)\n",
    "        Flux.update!(opt_state, net, grads[1])\n",
    "    end\n",
    "    \n",
    "    loss, acc, _ = loss_and_accuracy(net, train_data)\n",
    "    test_loss, test_acc, _ = loss_and_accuracy(net, test_data)\n",
    "    @info epoch acc test_acc\n",
    "    nt = (; epoch, loss, acc, test_loss, test_acc) \n",
    "    push!(train_log, nt)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab6d130e-1436-4ec9-8dc1-d5af2540b259",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hcat(Flux.onecold(y1hat, 0:9), Flux.onecold(y1, 0:9)) = [9 3]\n",
      "loss_and_accuracy(net, train_data) = (loss = 0.19802083f0, acc = 94.27, split = :train)\n"
     ]
    }
   ],
   "source": [
    "Flux.reset!(net)\n",
    "x1, y1 = first(loader(train_data)); # (28×28×1×1 Array{Float32, 3}, 10×1 OneHotMatrix(::Vector{UInt32}))\n",
    "y1hat = net(x1[  1:196,:])\n",
    "y2hat = net(x1[197:392,:])\n",
    "y3hat = net(x1[393:588,:])\n",
    "y4hat = net(x1[589:end,:])\n",
    "@show hcat(Flux.onecold(y1hat, 0:9), Flux.onecold(y1, 0:9))\n",
    "\n",
    "@show loss_and_accuracy(net, train_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5719344c-316a-4f40-a6f0-e7252d8825f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
